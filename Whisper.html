<!DOCTYPE html><html data-bs-theme="dark" lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no"><title>AIITK Whisper API Documentation</title><meta name="twitter:description" content="AI Integration toolkit plugin for Unreal Engine."><meta name="twitter:image" content="https://knooblegooble.com/AIITKDocs/assets/img/android-chrome-512x512.png"><meta property="og:image" content="https://knooblegooble.com/AIITKDocs/assets/img/android-chrome-512x512.png"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="AIITK for Unreal Engine"><meta name="description" content="Utilizing AIITK Plugin Functions for Enhanced Integration with OpenAI's Whisper API"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="assets/img/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="16x16" href="assets/img/favicon-16x16.png"><link rel="icon" type="image/png" sizes="16x16" href="assets/img/favicon-16x16.png" media="(prefers-color-scheme: dark)"><link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png"><link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png" media="(prefers-color-scheme: dark)"><link rel="icon" type="image/png" sizes="180x180" href="assets/img/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="192x192" href="assets/img/android-chrome-192x192.png"><link rel="icon" type="image/png" sizes="512x512" href="assets/img/android-chrome-512x512.png"><link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css"><link rel="stylesheet" href="assets/fonts/fontawesome-all.min.css"><link rel="stylesheet" href="assets/css/styles.min.css"></head><body class="text-dark" id="page-top"><div id="wrapper" style="overflow: visible;"><div id="navbar-wrapper" style="position: sticky;"><nav class="navbar navbar-expand fixed-top accordion bg-gradient-primary p-0 navbar-dark" data-bs-spy="scroll" style="font-family: Abel, sans-serif;background: linear-gradient(black 54%, white 93%);position: sticky;display: flex;max-width: 130px;min-width: 130px;"><div class="container-fluid d-flex flex-column p-0"><a href="index.html"><img class="rounded d-flex align-items-xl-center" src="assets/img/V2LogoFinal.png" width="100" height="100" style="border:4px ridge #5e5e5e;margin:24px;"></a><div class="col-xl-11" style="margin: 12px;margin-bottom: 844px;"><div class="vstack"><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-1" href="#collapse-1" role="button">Introduction</a><div class="collapse" id="collapse-1"><div class="vstack text-center"><a href="index.html#Introduction">Introduction</a><a href="index.html#Philosophy">Philosophy</a><a href="index.html#MainClasses">Main Classes</a><a href="index.html#AddingAPIKeys">Adding API keys</a><a href="index.html#WhereToAPIKey">Where do I get my API keys?</a></div></div></div><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-2" href="#collapse-2" role="button">Getting Started</a><div class="collapse" id="collapse-2"><div class="vstack text-center"><a href="GettingStarted.html#GettingStarted">Getting Started</a><a href="GettingStarted.html#How-To-Find-Examples">Find Examples</a><a href="GettingStarted.html#AIITKComponentBP">AIITKComponentBP</a><a href="GettingStarted.html#SendingARequest">Sending A Request</a><a href="GettingStarted.html#Parameters">Parameters</a></div></div></div><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-3" href="#collapse-3" role="button">ChatGPT</a><div class="collapse" id="collapse-3"><div class="vstack text-center"><a href="ChatGPT.html#ChatGPT">ChatGPT</a><a href="ChatGPT.html#GPTParams">GPT Params</a><a href="ChatGPT.html#TextGeneration">Text Generation</a><a href="ChatGPT.html#HandlingResponses">Handle Responses</a><a href="ChatGPT.html#GPTFunctions">GPT Functions</a><a href="ChatGPT.html#ParsingFunctions">Parsing Functions</a></div></div></div><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-7" href="#collapse-7" role="button">DallE</a><div class="collapse" id="collapse-7"><div class="vstack text-center"><a href="DallE.html#DallE">DallE</a><a href="DallE.html#DallEParams">DallE Params</a><a href="DallE.html#ImageGeneration">Image Generation</a><a href="DallE.html#DallEResponses">DallE Responses</a></div></div></div><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-6" href="#collapse-6" role="button">Whisper</a><div class="collapse" id="collapse-6"><div class="vstack text-center"><a href="Whisper.html#Whisper">Whisper</a><a href="Whisper.html#WhisperParams">Whisper Params</a><a href="Whisper.html#Voice-Transcription">Voice Transcription</a><a href="Whisper.html#RecordingAudio">Recording Voice</a></div></div></div><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-5" href="#collapse-5" role="button">Text To Speech</a><div class="collapse" id="collapse-5"><div class="vstack text-center"><a href="TextToSpeech.html#TTS">Text To Speech</a><a href="TextToSpeech.html#OAITTSParams">OpenAITTS Params</a><a href="TextToSpeech.html#ElevenLabsParams">11Labs Params</a><a href="TextToSpeech.html#VoiceGeneration">Voice Generation</a><a href="TextToSpeech.html#TTSResponses">TTS Responses</a><a href="TextToSpeech.html#TTSExperiment">Experimental</a></div></div></div><div><a class="btn btn-sm text-uppercase d-flex justify-content-center" data-bs-toggle="collapse" aria-expanded="false" aria-controls="collapse-4" href="#collapse-4" role="button">FAQ</a><div class="collapse" id="collapse-4"><p>Coming Soon</p></div></div></div></div></div></nav></div><div class="d-flex flex-column" id="content-wrapper"><div id="content"><div class="container-fluid"><div class="caption v-middle text-center">
  <h1 class="cd-headline clip">
    <span class="blc">AIITK::</span>
    <span class="cd-words-wrapper">
      <b class="is-visible">Text Generation</b>
      <b>Voice Transcription</b>
      <b>Text-To-Speech</b>
	  <b>Image Generation</b>

    </span>
  </h1>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<h1 class="text-dark mb-1" id="Whisper">Whisper</h1><h4 class="text-start" style="padding-bottom: 44px;">Whisper is designed to transcribe spoken words into text. This API is particularly useful for converting voice recorded at runtime into text to be sent to ChatGPT.</h4><ul class="font-monospace text-bg-light" id="WhisperParams" style="background:var(--bs-secondary-bg);border-radius:16px;border-width:5px;border-style:double;padding:33px;padding-top:13px;max-width:800px;"><li><span style="color:rgb(0, 0, 0);">WhisperParams</span><ul><li><span style="color:rgb(0, 89, 202);">APIKey</span>: Key for OpenAI API authentication. Set this in the project settings.</li><li><span style="color:rgb(0, 89, 202);">FilePath</span>: The path where the audio file is located, relative to the project directory. Format example: "YourProjDir/Sounds/YouVoice.wav".</li><li><span style="color:rgb(0, 89, 202);">ResponseFormat</span>: The format of the transcript output. Possible values include json, text, srt, verbose_json, or vtt. Defaults to json if not specified.</li><li><span style="color:rgb(0, 89, 202);">Model</span>: ID of the model to use for transcription. Currently, only "whisper-1" is available.</li><li><span style="color:rgb(0, 89, 202);">Endpoint</span>: Specifies the action to be performed. In this case, "Transcription" indicates that the audio file will be transcribed.</li><li><span style="color:rgb(0, 89, 202);">Language</span>: The language of the input audio in ISO-639-1 format. Providing the input language can improve accuracy and latency. This parameter is optional.</li><li><span style="color:rgb(0, 89, 202);">Prompt</span>: An optional text input to guide the model's style or to continue a previous audio segment. The prompt should match the language of the audio.</li><li><span style="color:rgb(0, 89, 202);">Temperature</span>: A value between 0 and 1 that sets the sampling temperature. Higher values make the output more random, while lower values result in more focused and deterministic output. Defaults to 0, which lets the model automatically increase the temperature based on log probability thresholds.</li></ul></li></ul><h3 class="text-dark" id="Voice-Transcription" style="margin-bottom: 20px;margin-top: 42px;">Voice Transcription</h3><h5 class="text-primary">RequestWhisperTranscript/SendRequestToWhisper (AIITKComponentBP)</h5><p>The <em>RequestWhisperTranscript </em>function takes a given .wav file and sends it to the Whisper API to transcribe into text.</p><section class="photo-gallery py-4 py-xl-5" style="padding-top: 0px;margin-bottom: -11px;margin-top: -16px;"><div class="container-fluid p-0" style="margin-right: 0px;"><div class="row g-0 row-cols-1 row-cols-md-2 row-cols-xl-3 photos" data-bss-baguettebox="" style="margin-top: -15px;"><div class="col-xl-6 item"><a href="assets/img/clipboard-image-44.png"><img class="img-fluid" src="assets/img/clipboard-image-44.png" width="478" height="262" style="padding: 6px;"></a><a href="assets/img/clipboard-image-45.png"><img class="img-fluid" src="assets/img/clipboard-image-45.png" width="478" height="262" style="padding: 6px;"></a></div></div></div></section><h3 class="text-dark" id="RecordingAudio" style="margin-bottom: 20px;margin-top: 42px;">Recording/Saving Audio</h3><p>To send the audio to get transcribed you first need a way to record the audio. These are the functions you will need to save your voice (or whatever you want) to the disk. I would recommend using the functions in AIITKComponentBP to start and stop audio capture for quick integration. AIITK utilizes the default Audio Capture plugin that’s now included with recent versions of Unreal. You can learn more about that here: <a href="https://docs.unrealengine.com/5.3/en-US/overview-of-submixes-in-unreal-engine/">Submix Overview</a></p><p><strong>*With StopAudioCaptureAndSave you only need to supply a filename, the default WAVFilePath output is YourBaseDirectory/Sounds/YourFileName.wav</strong></p><section class="photo-gallery py-4 py-xl-5" style="max-width: 700px;margin-top: -17px;"><div class="container-fluid p-0"><div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 photos" data-bss-baguettebox="" style="margin-top: -15px;"><div class="col-xl-6 item"><a href="assets/img/clipboard-image-47.png"><img class="img-fluid" src="assets/img/clipboard-image-47.png" style="padding: 5px;min-width: 450px;"></a><a href="assets/img/clipboard-image-46.png"><img class="img-fluid" src="assets/img/clipboard-image-46.png" style="padding: 5px;"></a></div></div></div></section><p style="margin-bottom: 1px;">TheAIITKComponentBP uses RecordingSubmix by default. This submix essentially mutes the game audio and only allows the default recording device input (typically the same as your Windows default) to be heard on this track.</p><section class="photo-gallery py-4 py-xl-5" style="max-width: 700px;"><div class="container-fluid p-0"><div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 photos" data-bss-baguettebox="" style="margin-top: -15px;"><div class="col-xl-6 item"><a href="assets/img/clipboard-image-48.png"><img class="img-fluid" src="assets/img/clipboard-image-48.png" style="padding: 5px;min-width: 450px;"></a></div></div></div></section><p style="margin-bottom: 1px;">Recording audio is mostly the same process as you would find with the Audio Capture plugin as it relies on it. You will find a WhisperAudioCaptureComponent subclass that clears up some naming confusion and allows you to easily set the desired submix if you need an alternative recording method.</p><section class="photo-gallery py-4 py-xl-5" style="max-width: 700px;"><div class="container-fluid p-0"><div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 photos" data-bss-baguettebox="" style="margin-top: -15px;"><div class="col-xl-6 item"><a href="assets/img/clipboard-image-49.png"><img class="img-fluid" src="assets/img/clipboard-image-49.png" style="padding: 5px;min-width: 586px;"></a></div></div></div></section></div></div><footer class="font-monospace bg-white sticky-footer" style="margin-top: 61px;"><div class="text-center my-auto copyright" style="padding-top: 0px;padding-bottom: 26px;"><span class="font-monospace" style="text-shadow: 22px 0px 0px rgb(255,15,0), 44px 0px rgb(255,92,0), 66px 0px rgb(255,214,0), 88px 0px rgb(0,255,25), 109px 0px rgb(0,148,255), 130px 0px rgb(112,0,255), 151px 0px rgb(255,0,199);margin-right: 160px;">EOF</span></div><div class="container my-auto"><div class="text-center my-auto copyright"><div class="vstack"><span>Copyright © Kaleb Knoettgen 2024</span><span class="text-muted" style="padding-top: 7px;">Updated March 14th, 2024</span></div></div></div><a class="border rounded d-inline scroll-to-top" href="#page-top"><i class="fas fa-angle-up"></i></a></footer></div></div><script src="assets/bootstrap/js/bootstrap.min.js"></script><script src="assets/js/script.min.js"></script></body></html>